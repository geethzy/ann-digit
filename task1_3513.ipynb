{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part 2.1 - output prediction\n",
    "code and pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Activity 2.1**\n",
    "\n",
    "- Yapa WSPYGC\n",
    "\n",
    "- EG/2018/3513"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np #mathematical functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing training data (inputs and relevant output)\n",
    "inputs = np.array([[0, 0, 1],\n",
    "                   [1, 1, 1],\n",
    "                   [1, 0, 1],\n",
    "                   [0, 1, 1]])\n",
    "                   \n",
    "outputs = np.array([[0],\n",
    "                    [1],\n",
    "                    [1],\n",
    "                    [0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implementation of the neural network\n",
    "class NeuralNetwork:\n",
    "    def __init__(self):\n",
    "        # Define the number of input, hidden, and output neurons and learning rate\n",
    "        self.input_size = 3\n",
    "        self.hidden_size = 3\n",
    "        self.output_size = 1\n",
    "        self.learning_rate = 0.1\n",
    "\n",
    "        # Initialize weights and biases\n",
    "        # weight for input to hidden layer\n",
    "        self.weights_input_hidden = np.random.rand(self.input_size, self.hidden_size)\n",
    "        # bias for hidden layer\n",
    "        self.bias_hidden = np.random.rand(1, self.hidden_size)\n",
    "        # weight for hidden to output layer\n",
    "        self.weights_hidden_output = np.random.rand(self.hidden_size, self.output_size)\n",
    "        # bias for output layer\n",
    "        self.bias_output = np.random.rand(1, self.output_size)\n",
    "    \n",
    "    def sigmoid(self, x): #define sigmoid funtion\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_derivative(self, x):#define sigmoid derivative\n",
    "        return x * (1 - x)\n",
    "    \n",
    "    def forward(self, inputs):# implement forward pass of the NN\n",
    "        # input.weight+bias\n",
    "        self.hidden_layer_input = np.dot(inputs, self.weights_input_hidden) + self.bias_hidden\n",
    "        # sigmoid function to hidden layer \n",
    "        self.hidden_layer_output = self.sigmoid(self.hidden_layer_input)\n",
    "        # hidden.weight+bias\n",
    "        self.output_layer_input = np.dot(self.hidden_layer_output, self.weights_hidden_output) + self.bias_output\n",
    "        # sigmoid function to output layer \n",
    "        self.output_layer_output = self.sigmoid(self.output_layer_input)\n",
    "        return self.output_layer_output\n",
    "    \n",
    "    def backward(self, inputs, target, output): #implement forward pass of the NN to update weights\n",
    "        error = target - output #error\n",
    "        delta_output = error * self.sigmoid_derivative(output) #graident for output layer\n",
    "        error_hidden = delta_output.dot(self.weights_hidden_output.T) #error of hidden layer\n",
    "        delta_hidden = error_hidden * self.sigmoid_derivative(self.hidden_layer_output) #gradient for hidden layer\n",
    "\n",
    "        # Update weights and biases with learning rate and gradient descent\n",
    "        self.weights_hidden_output += self.hidden_layer_output.T.dot(delta_output) * self.learning_rate \n",
    "        self.bias_output += np.sum(delta_output, axis=0) * self.learning_rate \n",
    "        self.weights_input_hidden += self.learning_rate * np.outer(inputs, delta_hidden)\n",
    "        self.bias_hidden += np.sum(delta_hidden, axis=0) * self.learning_rate \n",
    "\n",
    "    \n",
    "    def train(self, inputs, outputs, epochs):\n",
    "        for epoch in range(epochs):#iterate over epochs\n",
    "            for i in range(len(inputs)):#batch training\n",
    "                # compute the predicted output for that input(Forward pass)\n",
    "                output = self.forward(inputs[i])\n",
    "                # Backward propogation and weight updates\n",
    "                self.backward(inputs[i], outputs[i], output)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Layer: weights_input_hidden\n",
      "Shape: (3, 3)\n",
      "==================================================\n",
      "Layer: bias_hidden\n",
      "Shape: (1, 3)\n",
      "==================================================\n",
      "Layer: weights_hidden_output\n",
      "Shape: (3, 1)\n",
      "==================================================\n",
      "Layer: bias_output\n",
      "Shape: (1, 1)\n",
      "==================================================\n",
      "Total Trainable Parameters: 16\n"
     ]
    }
   ],
   "source": [
    "nn_archi = NeuralNetwork()\n",
    "\n",
    "# Print the architecture \n",
    "for name, _ in nn_archi.__dict__.items():\n",
    "    if \"weights\" in name or \"bias\" in name:\n",
    "        print(f\"Layer: {name}\")\n",
    "        print(f\"Shape: {nn_archi.__dict__[name].shape}\")\n",
    "        print(\"=\" * 50)\n",
    "\n",
    "total_params = sum(np.prod(nn.__dict__[name].shape) for name, _ in nn.__dict__.items() if \"weights\" in name or \"bias\" in name)\n",
    "print(f\"Total Trainable Parameters: {total_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = NeuralNetwork() #create instance of Neural Network\n",
    "epochs = 1000000 #define epochs\n",
    "# epochs = 100000\n",
    "nn.train(inputs, outputs, epochs) #starts the training process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define different test input combinations \n",
    "test_inputs = np.array([[0, 0, 0],\n",
    "                        [1, 0, 0],\n",
    "                        [1, 1, 0],\n",
    "                        [0, 1, 0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: [0 0 0] Output: [[0.0106173]]\n",
      "Input: [1 0 0] Output: [[0.99916055]]\n",
      "Input: [1 1 0] Output: [[0.9990289]]\n",
      "Input: [0 1 0] Output: [[0.00900199]]\n"
     ]
    }
   ],
   "source": [
    "# predict output for different combinations in test_inputs\n",
    "for input_combination in test_inputs:\n",
    "    output = nn.forward(input_combination)\n",
    "    print(\"Input:\", input_combination, \"Output:\", output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
